#!/bin/bash
# cx-core postinst script
# Copyright 2025 AI Venture Holdings LLC
# SPDX-License-Identifier: BUSL-1.1

set -e

CX_USER="cx"
CX_GROUP="cx"
CX_CONFIG_DIR="/etc/cx"
CX_DATA_DIR="/var/lib/cx"
CX_LOG_DIR="/var/log/cx"
CX_CACHE_DIR="/var/cache/cx"

case "$1" in
    configure)
        # Create cx system group if it doesn't exist
        if ! getent group "$CX_GROUP" > /dev/null 2>&1; then
            addgroup --system "$CX_GROUP"
        fi

        # Create cx system user if it doesn't exist
        if ! getent passwd "$CX_USER" > /dev/null 2>&1; then
            adduser --system --ingroup "$CX_GROUP" \
                --home "$CX_DATA_DIR" \
                --no-create-home \
                --gecos "CX Package Manager" \
                "$CX_USER"
        fi

        # Create and set permissions on directories
        for dir in "$CX_CONFIG_DIR" "$CX_DATA_DIR" "$CX_LOG_DIR" "$CX_CACHE_DIR"; do
            if [ ! -d "$dir" ]; then
                mkdir -p "$dir"
            fi
        done

        # Set ownership - config readable by all, writable by root
        chown root:root "$CX_CONFIG_DIR"
        chmod 755 "$CX_CONFIG_DIR"

        # Data dir owned by cx user
        chown "$CX_USER:$CX_GROUP" "$CX_DATA_DIR"
        chmod 750 "$CX_DATA_DIR"

        # Log dir owned by cx, group readable
        chown "$CX_USER:$CX_GROUP" "$CX_LOG_DIR"
        chmod 750 "$CX_LOG_DIR"

        # Cache dir owned by cx
        chown "$CX_USER:$CX_GROUP" "$CX_CACHE_DIR"
        chmod 750 "$CX_CACHE_DIR"

        # Create profiles subdirectory
        if [ ! -d "$CX_CONFIG_DIR/profiles.d" ]; then
            mkdir -p "$CX_CONFIG_DIR/profiles.d"
        fi
        chmod 755 "$CX_CONFIG_DIR/profiles.d"

        # Initialize default configuration if not exists
        if [ ! -f "$CX_CONFIG_DIR/cx.yaml" ]; then
            cat > "$CX_CONFIG_DIR/cx.yaml" << 'EOF'
# CX Configuration
# See https://cxlinux-ai.com/docs/configuration for details

# LLM Provider Settings
llm:
  # Default provider: ollama (local), anthropic, openai
  default_provider: ollama

  # Ollama settings (local LLM)
  ollama:
    host: http://localhost:11434
    model: llama3.2:3b
    timeout: 120

  # API providers (requires API keys in environment or ~/.cx/env)
  # anthropic:
  #   model: claude-3-sonnet-20240229
  # openai:
  #   model: gpt-4-turbo-preview

# Security Settings
security:
  # Enable sandbox for package operations
  sandbox: true
  sandbox_provider: firejail

  # Require confirmation for system changes
  confirm_changes: true

  # Maximum packages per operation
  max_packages_per_operation: 20

# Logging
logging:
  level: INFO
  file: /var/log/cx/cx.log
  max_size_mb: 50
  backup_count: 5

# Cache Settings
cache:
  enabled: true
  directory: /var/cache/cx
  ttl_hours: 24

# Hardware Detection
hardware:
  auto_detect: true
  gpu_support: true
EOF
            chmod 644 "$CX_CONFIG_DIR/cx.yaml"
        fi

        # Create state file for tracking
        if [ ! -f "$CX_DATA_DIR/state.json" ]; then
            echo '{"version": "0.1.0", "first_run": true, "installed_at": "'$(date -Iseconds)'"}' \
                > "$CX_DATA_DIR/state.json"
            chown "$CX_USER:$CX_GROUP" "$CX_DATA_DIR/state.json"
            chmod 640 "$CX_DATA_DIR/state.json"
        fi

        # Install Python dependencies if needed (for packages not in apt)
        if command -v pip3 > /dev/null 2>&1; then
            # Install anthropic and openai if not available
            pip3 install --quiet --break-system-packages \
                anthropic>=0.18.0 openai>=1.0.0 2>/dev/null || true
        fi

        echo ""
        echo "=============================================="
        echo "  CX has been installed successfully!"
        echo "=============================================="
        echo ""
        echo "Quick start:"
        echo "  cx --help          Show available commands"
        echo "  cx ask 'what LLM providers are available?'"
        echo "  cx install nginx   Install nginx with AI assistance"
        echo ""
        echo "Configuration: $CX_CONFIG_DIR/cx.yaml"
        echo ""
        echo "For local LLM support, install Ollama:"
        echo "  curl -fsSL https://ollama.ai/install.sh | sh"
        echo "  ollama pull llama3.2:3b"
        echo ""
        ;;

    abort-upgrade|abort-remove|abort-deconfigure)
        ;;

    *)
        echo "postinst called with unknown argument \`$1'" >&2
        exit 1
        ;;
esac

#DEBHELPER#

exit 0
