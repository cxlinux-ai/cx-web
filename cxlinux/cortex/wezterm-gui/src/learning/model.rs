//! User Model
//!
//! Stores learned patterns and provides predictions.

use super::LearningError;
use chrono::{DateTime, Timelike, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::path::{Path, PathBuf};

/// User model for command prediction and suggestions
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UserModel {
    /// Model version
    version: u32,

    /// Last training timestamp
    last_trained: Option<DateTime<Utc>>,

    /// Command frequency counts
    command_frequency: HashMap<String, f32>,

    /// Command sequences (n-grams)
    common_sequences: Vec<CommandSequence>,

    /// Error patterns
    error_patterns: Vec<ErrorPattern>,

    /// Project-specific patterns
    project_contexts: HashMap<String, ProjectModel>,

    /// Time-of-day patterns
    time_patterns: HashMap<u32, Vec<(String, f32)>>,

    /// Command aliases/abbreviations learned
    aliases: HashMap<String, String>,

    /// N-gram model for command chains (prefix -> next commands with probabilities)
    #[serde(default)]
    ngram_model: HashMap<String, Vec<(String, f32)>>,

    /// Directory-specific command frequencies
    #[serde(default)]
    directory_commands: HashMap<String, HashMap<String, f32>>,

    /// Intent vocabulary for TF-IDF (word -> document frequency)
    #[serde(default)]
    intent_vocabulary: HashMap<String, f32>,

    /// Total documents (intents) for IDF calculation
    #[serde(default)]
    intent_doc_count: usize,

    /// Intent->command mappings with TF-IDF vectors
    #[serde(default)]
    intent_mappings: Vec<IntentMapping>,

    /// Error->fix mappings learned from successful corrections
    #[serde(default)]
    error_fixes: Vec<ErrorFix>,
}

/// Intent to command mapping with TF-IDF representation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IntentMapping {
    /// Natural language intent description
    pub intent: String,

    /// Tokenized intent terms
    pub tokens: Vec<String>,

    /// TF-IDF vector (term -> tf-idf score)
    pub tfidf_vector: HashMap<String, f32>,

    /// Target command
    pub command: String,

    /// How often this mapping was used successfully
    pub success_count: usize,

    /// Confidence score
    pub confidence: f32,
}

/// Error to fix mapping
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ErrorFix {
    /// Error pattern (generalized)
    pub error_pattern: String,

    /// Original failed command pattern
    pub failed_command: String,

    /// Successful fix command
    pub fix_command: String,

    /// How often this fix worked
    pub success_count: usize,

    /// Explanation of the fix
    pub explanation: Option<String>,
}

/// A command sequence pattern
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CommandSequence {
    /// The sequence of commands
    pub commands: Vec<String>,

    /// How often this sequence occurs
    pub frequency: f32,

    /// Confidence score
    pub confidence: f32,
}

/// An error pattern
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ErrorPattern {
    /// Command that caused the error
    pub command_pattern: String,

    /// Error message pattern
    pub error_pattern: String,

    /// Suggested fix
    pub suggested_fix: Option<String>,

    /// Explanation
    pub explanation: Option<String>,

    /// How often this error occurs
    pub frequency: usize,
}

/// Project-specific model
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct ProjectModel {
    /// Project path
    pub path: String,

    /// Common commands for this project
    pub commands: HashMap<String, f32>,

    /// Project type detected
    pub project_type: Option<String>,

    /// Custom aliases for this project
    pub aliases: HashMap<String, String>,
}

/// Command pattern for matching
#[derive(Debug, Clone)]
pub struct CommandPattern {
    /// Pattern string
    pub pattern: String,

    /// Matched command prefix
    pub prefix: String,

    /// Expected arguments
    pub args: Vec<String>,
}

/// Suggestion context
#[derive(Debug, Clone)]
pub struct SuggestionContext {
    /// Current working directory
    pub working_dir: Option<PathBuf>,

    /// Last command executed
    pub last_command: Option<String>,

    /// Last N commands (for sequence matching)
    pub recent_commands: Vec<String>,

    /// Current hour
    pub hour: u32,

    /// Partial input
    pub partial_input: Option<String>,

    /// Current error (if any)
    pub current_error: Option<String>,
}

impl Default for SuggestionContext {
    fn default() -> Self {
        Self {
            working_dir: std::env::current_dir().ok(),
            last_command: None,
            recent_commands: Vec::new(),
            hour: chrono::Local::now().hour(),
            partial_input: None,
            current_error: None,
        }
    }
}

/// A command suggestion
#[derive(Debug, Clone)]
pub struct Suggestion {
    /// Suggested command
    pub command: String,

    /// Confidence score (0.0 - 1.0)
    pub confidence: f32,

    /// Source of suggestion
    pub source: SuggestionSource,

    /// Brief explanation
    pub explanation: Option<String>,
}

/// Source of a suggestion
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SuggestionSource {
    /// Based on command frequency
    Frequency,
    /// Based on sequence pattern
    Sequence,
    /// Based on time of day
    TimePattern,
    /// Based on project context
    ProjectContext,
    /// Based on partial input completion
    Completion,
    /// Based on error fix
    ErrorFix,
}

impl UserModel {
    /// Create a new empty model
    pub fn new() -> Self {
        Self {
            version: 1,
            last_trained: None,
            command_frequency: HashMap::new(),
            common_sequences: Vec::new(),
            error_patterns: Vec::new(),
            project_contexts: HashMap::new(),
            time_patterns: HashMap::new(),
            aliases: HashMap::new(),
            ngram_model: HashMap::new(),
            directory_commands: HashMap::new(),
            intent_vocabulary: HashMap::new(),
            intent_doc_count: 0,
            intent_mappings: Vec::new(),
            error_fixes: Vec::new(),
        }
    }

    /// Load model from file or create new
    pub fn load_or_create(path: &Path) -> Self {
        if path.exists() {
            match std::fs::read_to_string(path) {
                Ok(content) => match serde_json::from_str(&content) {
                    Ok(model) => {
                        log::info!("Loaded user model from {}", path.display());
                        return model;
                    }
                    Err(e) => {
                        log::warn!("Failed to parse model: {}", e);
                    }
                },
                Err(e) => {
                    log::warn!("Failed to read model file: {}", e);
                }
            }
        }

        log::info!("Creating new user model");
        Self::new()
    }

    /// Save model to file
    pub fn save(&self, path: &Path) -> Result<(), LearningError> {
        let content = serde_json::to_string_pretty(self)
            .map_err(|e| LearningError::Serialization(e.to_string()))?;

        if let Some(parent) = path.parent() {
            std::fs::create_dir_all(parent)?;
        }

        std::fs::write(path, content)?;
        log::info!("Saved user model to {}", path.display());
        Ok(())
    }

    /// Get model version
    pub fn version(&self) -> u32 {
        self.version
    }

    /// Increment version
    pub fn increment_version(&mut self) {
        self.version += 1;
        self.last_trained = Some(Utc::now());
    }

    /// Get last training time
    pub fn last_trained(&self) -> Option<DateTime<Utc>> {
        self.last_trained
    }

    /// Update command frequency
    ///
    /// Returns true if command already existed, false if new
    pub fn update_command_frequency(&mut self, command: &str, learning_rate: f32) -> bool {
        let normalized = self.normalize_command(command);
        let exists = self.command_frequency.contains_key(&normalized);

        let entry = self.command_frequency.entry(normalized).or_insert(0.0);
        *entry = *entry * (1.0 - learning_rate) + learning_rate;

        exists
    }

    /// Normalize command for pattern matching
    fn normalize_command(&self, command: &str) -> String {
        // Extract just the command and first argument pattern
        let parts: Vec<&str> = command.split_whitespace().collect();
        match parts.len() {
            0 => String::new(),
            1 => parts[0].to_string(),
            _ => {
                // Keep command and generalize arguments
                let cmd = parts[0];
                let args = parts[1..]
                    .iter()
                    .map(|a| {
                        if a.starts_with('-') {
                            a.to_string()
                        } else if a.contains('/') || a.contains('.') {
                            "<path>".to_string()
                        } else {
                            "<arg>".to_string()
                        }
                    })
                    .collect::<Vec<_>>()
                    .join(" ");
                format!("{} {}", cmd, args)
            }
        }
    }

    /// Add a command sequence
    ///
    /// Returns true if this is a new sequence
    pub fn add_sequence(&mut self, sequence: Vec<String>) -> bool {
        // Check if sequence exists
        for existing in &mut self.common_sequences {
            if existing.commands == sequence {
                existing.frequency += 1.0;
                existing.confidence = (existing.confidence * 0.9 + 0.1).min(1.0);
                return false;
            }
        }

        // Add new sequence
        self.common_sequences.push(CommandSequence {
            commands: sequence,
            frequency: 1.0,
            confidence: 0.5,
        });

        true
    }

    /// Update time pattern
    pub fn update_time_pattern(&mut self, hour: u32, commands: &[String]) {
        // First normalize all commands
        let normalized_cmds: Vec<String> = commands
            .iter()
            .map(|cmd| self.normalize_command(cmd))
            .collect();

        let entry = self.time_patterns.entry(hour).or_default();

        for normalized in normalized_cmds {
            // Find or add command
            if let Some(existing) = entry.iter_mut().find(|(c, _)| *c == normalized) {
                existing.1 += 1.0;
            } else {
                entry.push((normalized, 1.0));
            }
        }

        // Sort by frequency and keep top 10
        entry.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
        entry.truncate(10);
    }

    /// Update project patterns
    pub fn update_project_patterns(&mut self, project: &str, commands: &[String]) {
        // First normalize all commands and detect project type
        let normalized_cmds: Vec<String> = commands
            .iter()
            .map(|cmd| self.normalize_command(cmd))
            .collect();
        let project_type = self.detect_project_type(commands);

        let entry = self
            .project_contexts
            .entry(project.to_string())
            .or_default();

        for normalized in normalized_cmds {
            let freq = entry.commands.entry(normalized).or_insert(0.0);
            *freq += 1.0;
        }

        // Set project type if not already set
        if entry.project_type.is_none() {
            entry.project_type = project_type;
        }
    }

    /// Detect project type from commands
    fn detect_project_type(&self, commands: &[String]) -> Option<String> {
        let mut indicators: HashMap<&str, usize> = HashMap::new();

        for cmd in commands {
            let cmd_lower = cmd.to_lowercase();
            if cmd_lower.contains("npm") || cmd_lower.contains("yarn") || cmd_lower.contains("node")
            {
                *indicators.entry("nodejs").or_default() += 1;
            }
            if cmd_lower.contains("python") || cmd_lower.contains("pip") {
                *indicators.entry("python").or_default() += 1;
            }
            if cmd_lower.contains("cargo") || cmd_lower.contains("rustc") {
                *indicators.entry("rust").or_default() += 1;
            }
            if cmd_lower.contains("go ") || cmd_lower.contains("go.mod") {
                *indicators.entry("go").or_default() += 1;
            }
            if cmd_lower.contains("docker") {
                *indicators.entry("docker").or_default() += 1;
            }
            if cmd_lower.contains("kubectl") || cmd_lower.contains("k8s") {
                *indicators.entry("kubernetes").or_default() += 1;
            }
        }

        indicators
            .into_iter()
            .max_by_key(|(_, count)| *count)
            .filter(|(_, count)| *count >= 2)
            .map(|(t, _)| t.to_string())
    }

    /// Add an error pattern
    ///
    /// Returns true if this is a new pattern
    pub fn add_error_pattern(&mut self, command: &str, error: &str) -> bool {
        // Generalize patterns
        let cmd_pattern = self.generalize_command_pattern(command);
        let err_pattern = self.generalize_error_pattern(error);

        // Check if pattern exists
        for existing in &mut self.error_patterns {
            if existing.command_pattern == cmd_pattern && existing.error_pattern == err_pattern {
                existing.frequency += 1;
                return false;
            }
        }

        // Add new pattern
        self.error_patterns.push(ErrorPattern {
            command_pattern: cmd_pattern,
            error_pattern: err_pattern,
            suggested_fix: self.generate_fix_suggestion(command, error),
            explanation: None,
            frequency: 1,
        });

        true
    }

    /// Generalize command for pattern matching
    fn generalize_command_pattern(&self, command: &str) -> String {
        let parts: Vec<&str> = command.split_whitespace().collect();
        if parts.is_empty() {
            return String::new();
        }

        // Keep command and flags, generalize arguments
        parts[0].to_string()
    }

    /// Generalize error message for pattern matching
    fn generalize_error_pattern(&self, error: &str) -> String {
        // Extract key error phrase
        let error_lower = error.to_lowercase();

        if error_lower.contains("permission denied") {
            return "permission denied".to_string();
        }
        if error_lower.contains("not found") {
            return "not found".to_string();
        }
        if error_lower.contains("no such file") {
            return "no such file".to_string();
        }
        if error_lower.contains("connection refused") {
            return "connection refused".to_string();
        }
        if error_lower.contains("syntax error") {
            return "syntax error".to_string();
        }

        // Fall back to first 50 chars
        error.chars().take(50).collect()
    }

    /// Generate fix suggestion for error
    fn generate_fix_suggestion(&self, command: &str, error: &str) -> Option<String> {
        let error_lower = error.to_lowercase();
        let cmd_parts: Vec<&str> = command.split_whitespace().collect();
        let base_cmd = cmd_parts.first().copied().unwrap_or("");

        if error_lower.contains("permission denied") {
            return Some(format!("sudo {}", command));
        }

        if error_lower.contains("not found") && base_cmd == "cd" {
            return Some("mkdir -p <directory>".to_string());
        }

        if error_lower.contains("command not found") {
            return Some(format!("which {} || apt search {}", base_cmd, base_cmd));
        }

        None
    }

    /// Suggest next command based on context
    pub fn suggest_next_command(&self, context: &SuggestionContext) -> Vec<Suggestion> {
        let mut suggestions = Vec::new();

        // 1. Sequence-based suggestions
        if let Some(ref recent) = context.last_command {
            for seq in &self.common_sequences {
                if seq.commands.len() >= 2 {
                    // Check if recent command matches start of sequence
                    for i in 0..seq.commands.len() - 1 {
                        if seq.commands[i] == *recent {
                            suggestions.push(Suggestion {
                                command: seq.commands[i + 1].clone(),
                                confidence: seq.confidence * 0.8,
                                source: SuggestionSource::Sequence,
                                explanation: Some(format!("Often follows '{}'", recent)),
                            });
                        }
                    }
                }
            }
        }

        // 2. Time-based suggestions
        if let Some(time_cmds) = self.time_patterns.get(&context.hour) {
            for (cmd, freq) in time_cmds.iter().take(3) {
                suggestions.push(Suggestion {
                    command: cmd.clone(),
                    confidence: (*freq / 100.0).min(0.7),
                    source: SuggestionSource::TimePattern,
                    explanation: Some(format!("Common at this hour")),
                });
            }
        }

        // 3. Project-based suggestions
        if let Some(ref dir) = context.working_dir {
            let project_key = dir
                .file_name()
                .map(|n| n.to_string_lossy().to_string())
                .unwrap_or_default();

            if let Some(project) = self.project_contexts.get(&project_key) {
                let mut project_cmds: Vec<_> = project.commands.iter().collect();
                project_cmds
                    .sort_by(|a, b| b.1.partial_cmp(a.1).unwrap_or(std::cmp::Ordering::Equal));

                for (cmd, freq) in project_cmds.iter().take(3) {
                    suggestions.push(Suggestion {
                        command: (*cmd).clone(),
                        confidence: (**freq / 100.0).min(0.7),
                        source: SuggestionSource::ProjectContext,
                        explanation: Some(format!("Common in this project")),
                    });
                }
            }
        }

        // 4. Error fix suggestions
        if let Some(ref error) = context.current_error {
            let err_pattern = self.generalize_error_pattern(error);

            for pattern in &self.error_patterns {
                if pattern.error_pattern == err_pattern {
                    if let Some(ref fix) = pattern.suggested_fix {
                        suggestions.push(Suggestion {
                            command: fix.clone(),
                            confidence: 0.8,
                            source: SuggestionSource::ErrorFix,
                            explanation: pattern.explanation.clone(),
                        });
                    }
                }
            }
        }

        // 5. Completion suggestions
        if let Some(ref partial) = context.partial_input {
            for (cmd, freq) in &self.command_frequency {
                if cmd.starts_with(partial) && cmd != partial {
                    suggestions.push(Suggestion {
                        command: cmd.clone(),
                        confidence: *freq,
                        source: SuggestionSource::Completion,
                        explanation: None,
                    });
                }
            }
        }

        // Sort by confidence and deduplicate
        suggestions.sort_by(|a, b| {
            b.confidence
                .partial_cmp(&a.confidence)
                .unwrap_or(std::cmp::Ordering::Equal)
        });

        // Deduplicate
        let mut seen = std::collections::HashSet::new();
        suggestions.retain(|s| seen.insert(s.command.clone()));

        // Limit results
        suggestions.truncate(10);

        suggestions
    }

    /// Explain an error based on learned patterns
    pub fn explain_error(&self, error: &str) -> Option<String> {
        let err_pattern = self.generalize_error_pattern(error);

        for pattern in &self.error_patterns {
            if pattern.error_pattern == err_pattern {
                let mut explanation = String::new();

                if let Some(ref exp) = pattern.explanation {
                    explanation.push_str(exp);
                } else {
                    explanation.push_str(&format!(
                        "This error '{}' is commonly caused by '{}' commands.",
                        pattern.error_pattern, pattern.command_pattern
                    ));
                }

                if let Some(ref fix) = pattern.suggested_fix {
                    explanation.push_str(&format!("\nSuggested fix: {}", fix));
                }

                return Some(explanation);
            }
        }

        None
    }

    /// Predict intent from partial input
    pub fn predict_intent(&self, partial: &str) -> Vec<String> {
        let mut predictions = Vec::new();

        // Check command frequency
        for (cmd, _) in &self.command_frequency {
            if cmd.starts_with(partial) {
                predictions.push(cmd.clone());
            }
        }

        // Check aliases
        for (alias, cmd) in &self.aliases {
            if alias.starts_with(partial) {
                predictions.push(cmd.clone());
            }
        }

        predictions.sort();
        predictions.dedup();
        predictions.truncate(10);

        predictions
    }

    // =========================================================================
    // N-gram Model Methods
    // =========================================================================

    /// Update n-gram model with a command sequence
    pub fn update_ngram(&mut self, prev_command: &str, next_command: &str, learning_rate: f32) {
        let prev_normalized = self.normalize_command(prev_command);
        let next_normalized = self.normalize_command(next_command);

        let entry = self.ngram_model.entry(prev_normalized).or_default();

        // Find or add the next command
        if let Some(existing) = entry.iter_mut().find(|(cmd, _)| *cmd == next_normalized) {
            existing.1 = existing.1 * (1.0 - learning_rate) + learning_rate;
        } else {
            entry.push((next_normalized, learning_rate));
        }

        // Sort by probability and keep top 10
        entry.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
        entry.truncate(10);
    }

    /// Get predicted next commands based on n-gram model
    pub fn predict_next_ngram(&self, current_command: &str) -> Vec<(String, f32)> {
        let normalized = self.normalize_command(current_command);

        self.ngram_model
            .get(&normalized)
            .cloned()
            .unwrap_or_default()
    }

    /// Update directory-specific command frequency
    pub fn update_directory_command(&mut self, directory: &str, command: &str, learning_rate: f32) {
        let normalized_cmd = self.normalize_command(command);
        let dir_key = self.extract_directory_key(directory);

        let dir_cmds = self.directory_commands.entry(dir_key).or_default();
        let freq = dir_cmds.entry(normalized_cmd).or_insert(0.0);
        *freq = *freq * (1.0 - learning_rate) + learning_rate;
    }

    /// Extract a normalized directory key (last 2 path components)
    fn extract_directory_key(&self, path: &str) -> String {
        let path = std::path::Path::new(path);
        let components: Vec<_> = path
            .components()
            .rev()
            .take(2)
            .collect::<Vec<_>>()
            .into_iter()
            .rev()
            .collect();

        components
            .iter()
            .map(|c| c.as_os_str().to_string_lossy().to_string())
            .collect::<Vec<_>>()
            .join("/")
    }

    /// Get commands common in a directory context
    pub fn get_directory_commands(&self, directory: &str) -> Vec<(String, f32)> {
        let dir_key = self.extract_directory_key(directory);

        self.directory_commands
            .get(&dir_key)
            .map(|cmds| {
                let mut sorted: Vec<_> = cmds.iter().map(|(k, v)| (k.clone(), *v)).collect();
                sorted.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));
                sorted
            })
            .unwrap_or_default()
    }

    // =========================================================================
    // TF-IDF Intent Prediction Methods
    // =========================================================================

    /// Tokenize text for TF-IDF (lowercase, split on whitespace/punctuation)
    fn tokenize(&self, text: &str) -> Vec<String> {
        text.to_lowercase()
            .split(|c: char| c.is_whitespace() || c.is_ascii_punctuation())
            .filter(|s| !s.is_empty() && s.len() > 1)
            .map(|s| s.to_string())
            .collect()
    }

    /// Calculate term frequency for tokens
    fn calculate_tf(&self, tokens: &[String]) -> HashMap<String, f32> {
        let mut tf: HashMap<String, f32> = HashMap::new();
        let total = tokens.len() as f32;

        for token in tokens {
            *tf.entry(token.clone()).or_insert(0.0) += 1.0;
        }

        // Normalize by total tokens
        for freq in tf.values_mut() {
            *freq /= total;
        }

        tf
    }

    /// Calculate IDF for a term
    fn calculate_idf(&self, term: &str) -> f32 {
        let doc_freq = self.intent_vocabulary.get(term).copied().unwrap_or(0.0);
        if doc_freq == 0.0 || self.intent_doc_count == 0 {
            return 0.0;
        }

        ((self.intent_doc_count as f32) / doc_freq).ln() + 1.0
    }

    /// Calculate TF-IDF vector for tokens
    fn calculate_tfidf(&self, tokens: &[String]) -> HashMap<String, f32> {
        let tf = self.calculate_tf(tokens);
        let mut tfidf = HashMap::new();

        for (term, tf_score) in tf {
            let idf = self.calculate_idf(&term);
            if idf > 0.0 {
                tfidf.insert(term, tf_score * idf);
            }
        }

        tfidf
    }

    /// Calculate cosine similarity between two TF-IDF vectors
    fn cosine_similarity(&self, vec1: &HashMap<String, f32>, vec2: &HashMap<String, f32>) -> f32 {
        let mut dot_product = 0.0;
        let mut norm1 = 0.0;
        let mut norm2 = 0.0;

        for (term, score1) in vec1 {
            norm1 += score1 * score1;
            if let Some(score2) = vec2.get(term) {
                dot_product += score1 * score2;
            }
        }

        for score2 in vec2.values() {
            norm2 += score2 * score2;
        }

        if norm1 == 0.0 || norm2 == 0.0 {
            return 0.0;
        }

        dot_product / (norm1.sqrt() * norm2.sqrt())
    }

    /// Add an intent->command mapping
    pub fn add_intent_mapping(&mut self, intent: &str, command: &str) {
        let tokens = self.tokenize(intent);

        // Update vocabulary (document frequency)
        let unique_tokens: std::collections::HashSet<_> = tokens.iter().cloned().collect();
        for token in &unique_tokens {
            *self.intent_vocabulary.entry(token.clone()).or_insert(0.0) += 1.0;
        }
        self.intent_doc_count += 1;

        // Calculate TF-IDF for this intent
        let tfidf_vector = self.calculate_tfidf(&tokens);

        // Check if mapping exists
        for existing in &mut self.intent_mappings {
            if existing.intent == intent && existing.command == command {
                existing.success_count += 1;
                existing.confidence = (existing.confidence * 0.9 + 0.1).min(1.0);
                existing.tfidf_vector = tfidf_vector;
                return;
            }
        }

        // Add new mapping
        self.intent_mappings.push(IntentMapping {
            intent: intent.to_string(),
            tokens,
            tfidf_vector,
            command: command.to_string(),
            success_count: 1,
            confidence: 0.5,
        });
    }

    /// Find commands matching a natural language query using TF-IDF similarity
    pub fn find_intent_matches(&self, query: &str, threshold: f32) -> Vec<(String, f32)> {
        let query_tokens = self.tokenize(query);
        let query_tfidf = self.calculate_tfidf(&query_tokens);

        if query_tfidf.is_empty() {
            return Vec::new();
        }

        let mut matches: Vec<(String, f32)> = self
            .intent_mappings
            .iter()
            .filter_map(|mapping| {
                let similarity = self.cosine_similarity(&query_tfidf, &mapping.tfidf_vector);
                if similarity >= threshold {
                    // Boost by confidence and success count
                    let score = similarity
                        * mapping.confidence
                        * (1.0 + (mapping.success_count as f32).ln().max(0.0) * 0.1);
                    Some((mapping.command.clone(), score))
                } else {
                    None
                }
            })
            .collect();

        // Sort by score descending
        matches.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

        // Deduplicate commands, keeping highest score
        let mut seen = std::collections::HashSet::new();
        matches.retain(|(cmd, _)| seen.insert(cmd.clone()));

        matches.truncate(10);
        matches
    }

    // =========================================================================
    // Error->Fix Learning Methods
    // =========================================================================

    /// Learn an error->fix mapping from a successful correction
    pub fn learn_error_fix(
        &mut self,
        failed_command: &str,
        error_message: &str,
        fix_command: &str,
    ) {
        let error_pattern = self.generalize_error_pattern(error_message);
        let failed_pattern = self.generalize_command_pattern(failed_command);

        // Check if mapping exists
        for existing in &mut self.error_fixes {
            if existing.error_pattern == error_pattern && existing.failed_command == failed_pattern
            {
                if existing.fix_command == fix_command {
                    existing.success_count += 1;
                }
                return;
            }
        }

        // Generate explanation
        let explanation = self.generate_fix_explanation(failed_command, error_message, fix_command);

        // Add new mapping
        self.error_fixes.push(ErrorFix {
            error_pattern,
            failed_command: failed_pattern,
            fix_command: fix_command.to_string(),
            success_count: 1,
            explanation,
        });
    }

    /// Generate an explanation for a fix
    fn generate_fix_explanation(
        &self,
        failed_command: &str,
        error: &str,
        fix_command: &str,
    ) -> Option<String> {
        let error_lower = error.to_lowercase();
        let failed_parts: Vec<&str> = failed_command.split_whitespace().collect();
        let fix_parts: Vec<&str> = fix_command.split_whitespace().collect();

        // Check for sudo fix
        if fix_parts.first() == Some(&"sudo") && failed_parts.first() != Some(&"sudo") {
            return Some("Added sudo for elevated permissions".to_string());
        }

        // Check for typo correction
        if failed_parts.len() == fix_parts.len() {
            let diffs: Vec<_> = failed_parts
                .iter()
                .zip(fix_parts.iter())
                .filter(|(a, b)| a != b)
                .collect();
            if diffs.len() == 1 {
                return Some(format!("Corrected '{}' to '{}'", diffs[0].0, diffs[0].1));
            }
        }

        // Check for missing argument
        if fix_parts.len() > failed_parts.len() {
            return Some("Added missing argument(s)".to_string());
        }

        // Check for path fix
        if error_lower.contains("no such file") || error_lower.contains("not found") {
            return Some("Fixed file path or created missing resource".to_string());
        }

        None
    }

    /// Get fix suggestions for an error
    pub fn get_error_fixes(&self, error: &str, failed_command: Option<&str>) -> Vec<&ErrorFix> {
        let error_pattern = self.generalize_error_pattern(error);
        let failed_pattern = failed_command.map(|c| self.generalize_command_pattern(c));

        let mut fixes: Vec<_> = self
            .error_fixes
            .iter()
            .filter(|fix| {
                fix.error_pattern == error_pattern
                    && (failed_pattern.is_none()
                        || failed_pattern.as_ref() == Some(&fix.failed_command))
            })
            .collect();

        // Sort by success count
        fixes.sort_by(|a, b| b.success_count.cmp(&a.success_count));
        fixes
    }

    /// Apply decay to all frequencies
    pub fn apply_decay(&mut self, rate: f32) {
        for freq in self.command_frequency.values_mut() {
            *freq *= rate;
        }

        for seq in &mut self.common_sequences {
            seq.frequency *= rate;
        }

        for (_, cmds) in &mut self.time_patterns {
            for (_, freq) in cmds {
                *freq *= rate;
            }
        }
    }

    /// Prune infrequent patterns
    ///
    /// Returns number of patterns removed
    pub fn prune_patterns(&mut self, min_occurrences: usize) -> usize {
        let threshold = min_occurrences as f32;
        let mut removed = 0;

        // Prune command frequency
        let before = self.command_frequency.len();
        self.command_frequency.retain(|_, v| *v >= threshold * 0.1);
        removed += before - self.command_frequency.len();

        // Prune sequences
        let before = self.common_sequences.len();
        self.common_sequences.retain(|s| s.frequency >= threshold);
        removed += before - self.common_sequences.len();

        // Prune error patterns
        let before = self.error_patterns.len();
        self.error_patterns
            .retain(|p| p.frequency >= min_occurrences);
        removed += before - self.error_patterns.len();

        removed
    }
}

impl Default for UserModel {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_user_model_new() {
        let model = UserModel::new();
        assert_eq!(model.version(), 1);
    }

    #[test]
    fn test_update_command_frequency() {
        let mut model = UserModel::new();

        let is_new = model.update_command_frequency("ls -la", 0.1);
        assert!(!is_new);

        let is_new = model.update_command_frequency("ls -la", 0.1);
        assert!(is_new);
    }

    #[test]
    fn test_add_sequence() {
        let mut model = UserModel::new();

        let is_new = model.add_sequence(vec!["git add".to_string(), "git commit".to_string()]);
        assert!(is_new);

        let is_new = model.add_sequence(vec!["git add".to_string(), "git commit".to_string()]);
        assert!(!is_new);
    }

    #[test]
    fn test_predict_intent() {
        let mut model = UserModel::new();
        model.update_command_frequency("ls -la", 0.1);
        model.update_command_frequency("less file.txt", 0.1);

        let predictions = model.predict_intent("l");
        assert!(predictions.iter().any(|p| p.starts_with("l")));
    }

    #[test]
    fn test_error_pattern() {
        let mut model = UserModel::new();

        model.add_error_pattern("rm /protected", "Permission denied");

        let explanation = model.explain_error("Permission denied");
        assert!(explanation.is_some());
        assert!(explanation.unwrap().contains("sudo"));
    }
}
